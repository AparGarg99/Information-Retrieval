{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "l = os.listdir(\"folder\") # dir is your directory path\n",
    "n= len(l)\n",
    "k=[]\n",
    "for i in range(n):\n",
    "    x='t'+str(i+1)+'.txt'\n",
    "    f=open(x,'r')\n",
    "    l=[]\n",
    "    for i in f:\n",
    "        l.append(str(i))\n",
    "    for i in range(len(l)):\n",
    "        l[i]=l[i].strip()\n",
    "    a=\"\"\n",
    "    for i in range(len(l)):\n",
    "        a=a+str(l[i])+\" \"\n",
    "    for char in string.punctuation:\n",
    "        a=str(a.replace(char,\" \"))\n",
    "    k.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Hi', 'my', 'name', 'is', 'Apar', 'and', 'I', 'to', 'love', 'be', 'or', 'playing', 'not', 'to', 'football', 'be'], ['hello', 'see', 'you', 'later'], ['Myself', 'Sanskruti', 'to', 'be', 'or', 'not', 'to', 'be', 'I', 'am', 'crazy', 'about', 'about', 'badminton'], ['marvel', 'is', 'dead', 'i', 'adore', 'baseball']]\n"
     ]
    }
   ],
   "source": [
    "files=list(k)\n",
    "for j in range(len(k)):\n",
    "    files[j]=files[j].split()\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'Hi my name is Apar and I to love be or playing not to football be  ',\n",
       " 2: 'hello see you later ',\n",
       " 3: 'Myself Sanskruti to be or not to be I am crazy about about badminton  ',\n",
       " 4: 'marvel is dead i adore baseball  '}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens={}\n",
    "for i in range(1,len(k)+1):\n",
    "    tokens[i]=k[i-1]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index(tokens):\n",
    "    inverted_index = {}\n",
    "    wordCount = {}\n",
    "    for k, v in tokens.items():\n",
    "        for word in v.lower().split():\n",
    "            wordCount[word] = wordCount.get(word,0)+1\n",
    "            if inverted_index.get(word,False):\n",
    "                if k not in inverted_index[word]:\n",
    "                    inverted_index[word].append(k)\n",
    "            else:\n",
    "                inverted_index[word] = [k]\n",
    "    return inverted_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hi': [1],\n",
       " 'my': [1],\n",
       " 'name': [1],\n",
       " 'is': [1, 4],\n",
       " 'apar': [1],\n",
       " 'and': [1],\n",
       " 'i': [1, 3, 4],\n",
       " 'to': [1, 3],\n",
       " 'love': [1],\n",
       " 'be': [1, 3],\n",
       " 'or': [1, 3],\n",
       " 'playing': [1],\n",
       " 'not': [1, 3],\n",
       " 'football': [1],\n",
       " 'hello': [2],\n",
       " 'see': [2],\n",
       " 'you': [2],\n",
       " 'later': [2],\n",
       " 'myself': [3],\n",
       " 'sanskruti': [3],\n",
       " 'am': [3],\n",
       " 'crazy': [3],\n",
       " 'about': [3],\n",
       " 'badminton': [3],\n",
       " 'marvel': [4],\n",
       " 'dead': [4],\n",
       " 'adore': [4],\n",
       " 'baseball': [4]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst_list=create_index(tokens)\n",
    "pst_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter the word you want to search: apar\n",
      "present in Doc [1]\n"
     ]
    }
   ],
   "source": [
    "#boolean retrieval Query-single-word search\n",
    "s=input(\"enter the word you want to search: \")\n",
    "print('present in Doc',pst_list[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "present in Doc [1]\n"
     ]
    }
   ],
   "source": [
    "#boolean retrieval Query with logical operators\n",
    "\n",
    "def conjuctive(p1, p2):\n",
    "    i, j = 0, 0\n",
    "    int_set = list()\n",
    "    while i < len(p1) and j < len(p2):\n",
    "        if p1[i] == p2[j]:\n",
    "            int_set.append(p1[i])\n",
    "            i = i + 1\n",
    "            j = j + 1\n",
    "        elif p1[i] < p2[j]:\n",
    "            i = i + 1\n",
    "        else:\n",
    "            j = j + 1\n",
    "    return int_set\n",
    "\n",
    "def union(p1, p2):\n",
    "    i, j = 0, 0\n",
    "    uni_set = list()\n",
    "    while i < len(p1) and j < len(p2):\n",
    "        if p1[i] == p2[j]:\n",
    "            uni_set.append(p1[i])\n",
    "            i = i + 1\n",
    "            j = j + 1\n",
    "        elif p1[i] < p2[j]:\n",
    "            uni_set.append(p1[i])\n",
    "            i = i + 1\n",
    "        else:\n",
    "            uni_set.append(p2[j])\n",
    "            j = j + 1\n",
    "    return uni_set\n",
    "\n",
    "s = 'Sanskruti or football'.lower().split()\n",
    "if 'and' in s:\n",
    "    print(\"present in Doc\",conjuctive(pst_list[s[0]], pst_list[s[2]]))\n",
    "if 'or' in s:\n",
    "    print(\"present in Doc\",union(pst_list[s[0]], pst_list[s[2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter proximity of the two words: 6\n",
      "The given phrase is present in Document =  [1]\n"
     ]
    }
   ],
   "source": [
    "# Phrase Query and Proximity search\n",
    "d = dict()\n",
    "for k, v in pst_list.items():\n",
    "    d[k] = [[] for _ in range(len(files))]\n",
    "\n",
    "for k, v in d.items():\n",
    "    for i in range(len(files)):\n",
    "        for j in range(len(files[i])):\n",
    "            if files[i][j] == k: v[i].append(j)\n",
    "\n",
    "def phrase_query(a, k, b):\n",
    "    docs = []\n",
    "    l = list(zip(d[a], d[b])) \n",
    "    #print(l)\n",
    "    c = 1\n",
    "    for p, q in l:\n",
    "        if not p or not q: continue\n",
    "        for i in p:\n",
    "            if abs(i + k) in q or abs(i - k) in q:\n",
    "                docs.append(c)\n",
    "                break\n",
    "        c = c + 1\n",
    "    return docs\n",
    "\n",
    "\n",
    "k=int(input('enter proximity of the two words: '))\n",
    "if(k==1):\n",
    "    print(\"The given phrase is present in Document = \", phrase_query('love', k, 'football'))\n",
    "else:\n",
    "    print(\"The given proximity query is present in Document = \", phrase_query('love', k, 'football'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
